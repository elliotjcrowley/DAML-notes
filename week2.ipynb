{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd4f525",
   "metadata": {},
   "source": [
    "# DAML4  notes\n",
    "## Week 2  - Summarising and visualising data\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7e27d",
   "metadata": {},
   "source": [
    "## Summary statistics \n",
    "\n",
    "Given a tabular dataset, it can be useful to summarise key statistics of its variables to convey as much information as simply as possible. Python has excellent functionality for doing this.\n",
    "\n",
    "Let's load in the iris dataset that we've seen from the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loader for the iris dataset and import pandas and numpy\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert into dataframe with the columns as the variable names\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb2135",
   "metadata": {},
   "source": [
    "We can compute a range of summary statistics for all the variables in a single line using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e85d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045ef7f",
   "metadata": {},
   "source": [
    "If we have a variable represented as a numpy array, we can turn to numpy functions for a similar purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're going to generate 10000 dummy points\n",
    "# These are sampled from a normal distribution with mean 3, SD 2.2\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(3, 2.2, size=10000)\n",
    "\n",
    "# We're now going use numpy functions to compute the mean and SD\n",
    "# These should hopefully be similar to 3 and 2.2\n",
    "\n",
    "print(f\"Empirical mean of X is {X.mean()}\")\n",
    "print(f\"Empirical SD of X is {X.std()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d0409",
   "metadata": {},
   "source": [
    "We can use scipy to compute skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# A normal distribution has no skew, so we expect this to be around 0\n",
    "print(f\"Skew of X is {skew(X)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e7316",
   "metadata": {},
   "source": [
    "Given two variables $X$ and $Y$, the Pearson correlation coefficient $\\rho_{xy}$ gives a measure of how linear the relationship between them is. \n",
    "\n",
    "To demonstrate this, I am going to take the $X$ I made above, and create a $Y$ that is a linear transform of $X$. We should therefore expect $\\rho_{xy}=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0c3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Y which is linear in X\n",
    "Y = 5 * X - 2\n",
    "\n",
    "# This computes a 2x2 matrix where each element is rho_{i,j}\n",
    "corrs = np.corrcoef(X, Y)\n",
    "\n",
    "# We are interested in the off diagonal terms (which are identical)\n",
    "print(f\"rho_xy is {corrs[0,1]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030a533",
   "metadata": {},
   "source": [
    "This makes sense as there is a perfect linear relationship between X and Y. Let's now create a variable Z that has nothing to do with X and check its correlation with X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d166f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Z which has nothing to do with X\n",
    "Z = np.random.uniform(0, 1, size=10000)\n",
    "\n",
    "# This computes a 2x2 matrix where each element is rho_{i,j}\n",
    "corrs = np.corrcoef(X, Z)\n",
    "\n",
    "# We are interested in the off diagonal terms (which are identical)\n",
    "print(f\"rho_xz is {corrs[0,1]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7943e30",
   "metadata": {},
   "source": [
    "## Visualising data\n",
    "\n",
    "For plotting in Python there are two standard options. The first is to use [matplotlib](https://matplotlib.org), and the second is to used [seaborn](https://seaborn.pydata.org) which is based on matplotlib. Seaborn typically creates better-looking plots than matplotlib with less effort, but matplotlib is a lot more cutsomisable.\n",
    "\n",
    "I have used matplotlib for the vast majority of the plots in the lectures and labs, but you are more than welcome to use seaborn for the labs and tests if you prefer it.\n",
    "\n",
    "The following preamble changes the defaults for matplotlib figures so they are easier to read. You will see it a lot in my code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f503597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This just needs to be run once per instance.\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"lines.markersize\": 10,  # Big points\n",
    "        \"font.size\": 15,  # Larger font\n",
    "        \"xtick.major.size\": 5.0,  # Bigger xticks\n",
    "        \"ytick.major.size\": 5.0,  # Bigger yticks\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1082a5fc",
   "metadata": {},
   "source": [
    "I'll now provide code to recreate different plots from the lecture. The `fig, ax = plt.subplots()` that we use to create the figure and its axes looks a bit esoteric but you will get used to it! You can find a good explanation of why we're doing it [here](https://stackoverflow.com/questions/63039065/fig-ax-plt-subplots-meaning).\n",
    "\n",
    "### Bar plots\n",
    "\n",
    "These are useful for visualising the distribution of a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e09501",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Â Bar plot of lecture ratings\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Synthesise data\n",
    "opinions = [\"1 Awful\", \"2 Bad\", \"3 OK\", \"4 Good\", \"5 Great\"]\n",
    "tallies = [12, 5, 2, 10, 20]\n",
    "\n",
    "# Plot\n",
    "ax.bar(opinions, tallies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719afc88",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "\n",
    "These are useful for visualising the distribution of a continuous variable, although you may need to tweak the bin size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Histogram of exam results\n",
    "\n",
    "\n",
    "# Package for creating skewed data\n",
    "from scipy.stats import skewnorm\n",
    "\n",
    "# The number of bins. Feel free to change this!\n",
    "num_bins = 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Setting a seed so the plot looks the same each time\n",
    "np.random.seed(4)\n",
    "\n",
    "# Skewed data\n",
    "x = skewnorm.rvs(1, loc=60, scale=10, size=200)\n",
    "\n",
    "ax.hist(x, bins=num_bins)\n",
    "\n",
    "ax.set_xlabel(\"Marks\")\n",
    "ax.set_ylabel(\"Frequencies\")\n",
    "ax.set_title(f\"Exam marks (%) - {num_bins} bins\", fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def35ae3",
   "metadata": {},
   "source": [
    "### Scatter plots\n",
    "\n",
    "I would argue these are the most important plot of all. They let you compare measurements for different variables in either 2D or 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Petal length vs. petal width for irises (2D)\n",
    "\n",
    "# We loaded this above, but we'll do it again now\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Add a column with the species as an integer 0,1,2\n",
    "# We can use different colours for different species\n",
    "df.insert(4, \"species\", data.target)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[8,8])\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 0],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 0],\n",
    "    color=\"r\",\n",
    ")\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 1],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 1],\n",
    "    color=\"g\",\n",
    ")\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 2],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 2],\n",
    "    color=\"b\",\n",
    ")\n",
    "\n",
    "ax.legend(data.target_names)\n",
    "\n",
    "# Tidy up ticks (optional)\n",
    "ax.set_yticks([0, 1, 2, 3])\n",
    "\n",
    "# Label\n",
    "ax.set_title(\"Petal length vs. petal width of irises\")\n",
    "ax.set_xlabel(\"Petal length (cm)\")\n",
    "ax.set_ylabel(\"Petal width (cm)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Petal length vs. petal width vs. sepal length for irises (3D)\n",
    "\n",
    "# We have to make fig, ax in a slightly different way for 3D\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 0],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 0],\n",
    "    df[\"sepal length (cm)\"][df[\"species\"] == 0],\n",
    "    color=\"r\",\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 1],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 1],\n",
    "    df[\"sepal length (cm)\"][df[\"species\"] == 1],\n",
    "    color=\"g\",\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    df[\"petal length (cm)\"][df[\"species\"] == 2],\n",
    "    df[\"petal width (cm)\"][df[\"species\"] == 2],\n",
    "    df[\"sepal length (cm)\"][df[\"species\"] == 2],\n",
    "    color=\"b\",\n",
    ")\n",
    "ax.legend(data.target_names)\n",
    "\n",
    "# Label\n",
    "ax.set_title(\"Sepal Length vs. Petal length vs. petal width of irises\")\n",
    "ax.set_xlabel(\"Petal length (cm)\")\n",
    "ax.set_ylabel(\"Petal width (cm)\")\n",
    "ax.set_zlabel(\"Sepal length (cm)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665720de",
   "metadata": {},
   "source": [
    "### Box plots\n",
    "\n",
    "I do use seaborn for boxplots, as they look a lot better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e5c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Box plot of petal length for the iris dataset\n",
    "\n",
    "# import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x=df['petal length (cm)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Box plot of petal length for the iris dataset by species\n",
    "fig = plt.figure(figsize=(7, 8))\n",
    "sns.boxplot(y=df[\"petal length (cm)\"], x=df[\"species\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4594b748",
   "metadata": {},
   "source": [
    "### Heat maps\n",
    "\n",
    "Heat maps are a nice way to visualise the magnitude of quantities in a matrix. Here we are going to use seaborn to see how different attributes correlate for a penguin dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21997894",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Penguin correlation heatmap\n",
    "\n",
    "# Read pandas dataset from seaborn package\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Compute correlation matrix and plot using seaborn\n",
    "# Notice have used .corr() from pandas\n",
    "\n",
    "matrix = df.corr().round(2)\n",
    "sns.heatmap(matrix, annot=True, vmax=1, vmin=-1, center=0, cmap=\"vlag\").set(\n",
    "    title=\"Correlations for penguin attributes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d86791c",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "#### Written by Elliot J. Crowley and &copy; The University of Edinburgh 2022-23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
